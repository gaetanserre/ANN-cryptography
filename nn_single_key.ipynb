{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Char to byte and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char2byte(c):\n",
    "  byte = bin(int.from_bytes(c.encode(\"ascii\"), 'big'))[2:]\n",
    "  if len(byte) < 8: byte = \"\".join(['0' for _ in range(8-len(byte))])+byte\n",
    "  return np.array([int(b) for b in byte], dtype=np.float32)\n",
    "\n",
    "def byte2char(byte):\n",
    "  b = \"0b\" +\"\".join([str(int(b.item())) for b in byte])\n",
    "  n = int(b, 2)\n",
    "  return n.to_bytes((n.bit_length() + 7) // 8, \"big\").decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(symbols, nb, replace=True):\n",
    "  ids = np.random.choice(symbols.shape[0], nb, replace=replace)\n",
    "  return TensorDataset(th.from_numpy(symbols[ids]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(ann, symbols):\n",
    "  th_symbols = th.tensor(symbols).to(device)\n",
    "  pred_symbols = ann(th_symbols).round()\n",
    "  return (th.all(th_symbols == pred_symbols, dim=1).sum() / len(symbols)).item()\n",
    "\n",
    "def get_test_loss(\n",
    "    ann,\n",
    "    loss_recons,\n",
    "    loss_diff,\n",
    "    gamma,\n",
    "    chars,\n",
    "    batch_size\n",
    "):\n",
    "\n",
    "  ann.eval()\n",
    "\n",
    "  dataloader = DataLoader(chars, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "  avg_loss_recons = 0\n",
    "  avg_loss_diff = 0\n",
    "  nb_batch = 0\n",
    "  for data in dataloader:\n",
    "    nb_batch += 1\n",
    "\n",
    "    data        = data[0].to(device)\n",
    "    data_cipher = ann.cipher(data)\n",
    "    data_pred   = ann.decipher(data_cipher)\n",
    "\n",
    "    l_recons  = loss_recons(data_pred, data)\n",
    "    l_diff    = gamma*loss_diff(data_cipher, data)\n",
    "    l         = l_recons - l_diff\n",
    "    avg_loss_recons += l_recons.item()\n",
    "    avg_loss_diff   += l_diff.item()\n",
    "\n",
    "  ann.train()\n",
    "  return avg_loss_recons / nb_batch, avg_loss_diff / nb_batch\n",
    "\n",
    "\n",
    "def train(\n",
    "    ann,\n",
    "    loss_recons,\n",
    "    loss_diff,\n",
    "    acc_fun,\n",
    "    optimizer,\n",
    "    train_chars,\n",
    "    valid_chars,\n",
    "    test_chars,\n",
    "    batch_size,\n",
    "    nb_epochs=-1,\n",
    "    gamma=0.2,\n",
    "    verbose=False\n",
    "):\n",
    "\n",
    "  \"\"\"\n",
    "  Training loop\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  loss_recons: `[th.Tensor, th.Tensor] -> th.Tensor`\n",
    "      Evaluates the difference between the original data and the decrypted ones. To be minimized.\n",
    "  loss_diff: `[th.Tensor, th.Tensor] -> th.Tensor`\n",
    "      Evaluates the difference between the original data and the encrypted ones. To be maximized.\n",
    "  acc_fun: `[nn.Module, Iterable] -> float`\n",
    "      Evaluates the accuracy of the model on each possible symbol.\n",
    "  nb_epochs: `int`\n",
    "      Number of epochs. If -1, the training loop stops when the accuracy is 1.0. Default -1.\n",
    "  \"\"\"\n",
    "\n",
    "  ann.train()\n",
    "  train_losses = []\n",
    "  valid_losses = []\n",
    "  epoch = 0\n",
    "  while True:\n",
    "    dataloader = DataLoader(train_chars, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    if verbose:\n",
    "      print(f\"Epoch {epoch+1}\")\n",
    "\n",
    "    avg_loss_recons = 0\n",
    "    avg_loss_diff = 0\n",
    "    nb_batch = 0\n",
    "    for data in dataloader:\n",
    "      nb_batch += 1\n",
    "\n",
    "      data        = data[0].to(device)\n",
    "      data_cipher = ann.cipher(data)\n",
    "      data_pred   = ann.decipher(data_cipher)\n",
    "\n",
    "      l_recons  = loss_recons(data_pred, data)\n",
    "      l_diff    = gamma*loss_diff(data_cipher, data)\n",
    "      l         = l_recons - l_diff\n",
    "      avg_loss_recons += l_recons.item()\n",
    "      avg_loss_diff   += l_diff.item()\n",
    "      l.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "    train_losses                   .append((avg_loss_recons / nb_batch, avg_loss_diff / nb_batch))\n",
    "    val_loss_recons, val_loss_diff = get_test_loss(ann, loss_recons, loss_diff, gamma, valid_chars, batch_size)\n",
    "    valid_losses                   .append((val_loss_recons, val_loss_diff))\n",
    "    accuracy                       = acc_fun(ann) \n",
    "    if verbose:\n",
    "      print(f\"Train loss recons {avg_loss_recons / nb_batch:.4f} diff {avg_loss_diff / nb_batch:.4f}\")\n",
    "      print(f\"Valid loss recons {val_loss_recons:.4f} diff {val_loss_diff:.4f}\")\n",
    "      print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    epoch += 1\n",
    "    if epoch == nb_epochs or accuracy == 1: break\n",
    "\n",
    "  test_loss_recons, test_loss_diff = get_test_loss(ann, loss_recons, loss_diff, gamma, test_chars, batch_size)\n",
    "  if verbose:\n",
    "    print(f\"Test loss recons {test_loss_recons:.4f} diff {test_loss_diff:.4f}\")\n",
    "\n",
    "  return (test_loss_recons, test_loss_diff), train_losses, valid_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cipher and decipher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cipher(nn.Module):\n",
    "  def __init__(self, arch, latent_dim):\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    input_dim = 8\n",
    "    for a in arch:\n",
    "      layers.append(nn.Linear(input_dim, a))\n",
    "      input_dim = a\n",
    "    self.fcs = nn.Sequential(*layers)\n",
    "\n",
    "    self.last_fc = nn.Linear(input_dim, latent_dim)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    h = self.fcs(inputs)\n",
    "    h = self.last_fc(h)\n",
    "    return h\n",
    "  \n",
    "class Decipher(nn.Module):\n",
    "  def __init__(self, arch, latent_dim):\n",
    "    super().__init__()\n",
    "\n",
    "    layers = []\n",
    "    input_dim = latent_dim\n",
    "    for a in arch:\n",
    "      layers.append(nn.Linear(input_dim, a))\n",
    "      input_dim = a\n",
    "    self.fcs = nn.Sequential(*layers)\n",
    "\n",
    "    self.last_fc = nn.Linear(input_dim, 8)\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    h = self.fcs(inputs)\n",
    "    h = self.last_fc(h)\n",
    "    return th.sigmoid(h)\n",
    "\n",
    "class ANNCrypto(nn.Module):\n",
    "  def __init__(self, latent_dim, cipher_arch=[], decipher_arch=[]):\n",
    "    super().__init__()\n",
    "\n",
    "    self.cipher   = Cipher(cipher_arch, latent_dim)\n",
    "    self.decipher = Decipher(decipher_arch, latent_dim)\n",
    "  \n",
    "  def forward(self, inputs):\n",
    "    h = self.cipher(inputs)\n",
    "    return self.decipher(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt(ann, text):\n",
    "  text_byte   = th.tensor(np.array([char2byte(c) for c in text])).to(device)\n",
    "  cipher_byte = ann.cipher(text_byte)\n",
    "\n",
    "  return cipher_byte\n",
    "\n",
    "def decrypt(ann, cipher_byte):\n",
    "  text_byte   = ann.decipher(cipher_byte).round()\n",
    "\n",
    "  text = \"\"\n",
    "  for b in text_byte:\n",
    "    text += byte2char(b)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols       = np.array([char2byte(chr(c)) for c in range(32, 127)])\n",
    "train_dataset = create_dataset(symbols, len(symbols), replace=False)\n",
    "valid_dataset = create_dataset(symbols, len(symbols), replace=False)\n",
    "test_dataset  = create_dataset(symbols, len(symbols), replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model, the optimizer and the losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann         = ANNCrypto(8, [10], [10]).to(device)\n",
    "optimizer   = th.optim.Adam(ann.parameters(), lr=1e-4)\n",
    "loss_recons = th.nn.BCELoss()\n",
    "loss_diff   = th.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _ = train(\n",
    "            ann,\n",
    "            loss_recons,\n",
    "            loss_diff,\n",
    "            lambda ann: get_accuracy(ann, symbols),\n",
    "            optimizer,\n",
    "            train_dataset,\n",
    "            valid_dataset,\n",
    "            test_dataset,\n",
    "            nb_epochs=-1,\n",
    "            batch_size=len(symbols),\n",
    "            gamma=0.001,\n",
    "            verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Try to decrypt me!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_text  = \"Try to decrypt me!\"\n",
    "cipher_byte    = encrypt(ann, original_text)\n",
    "decrypted_text = decrypt(ann, cipher_byte)\n",
    "assert original_text == decrypted_text\n",
    "decrypted_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "caf294c8b7f99497ecf5c094d08c3d101cb799ecbd84d0a8d0493e84938aefcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
